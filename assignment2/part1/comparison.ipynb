{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "(a) (4 points) Plot for VGG11, VGG11 with batch normalization, ResNet18, ResNet34, DenseNet121 and MobileNet-v3-Small, the Top-1 accuracy on ImageNet vs the inference speed. The value for the Top-1 accuracy of each model can be found on the PyTorch website. Also plot the inference speed vs the number of parameters. Does it scale proportionately? Make sure to set the model on evaluation mode, use `torch.no_grad()` and a GPU. Report the inference speed in ms for one image. Average the inference speed across multiple forward passes. Shortly, describe the trends you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "# set the seed for reproducibility of the whole notebook\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():  # GPU operation have separate seed\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.determinstic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def vit_s_8():\n",
    "    \"\"\"ViT-S/8 is not a default torchvision model, so we provide it by timm\"\"\"\n",
    "    # Accuracy approximation comes from\n",
    "    # https://openreview.net/pdf?id=LtKcMgGOeLt\n",
    "    # and DINO\n",
    "    # https://arxiv.org/abs/2104.14294\n",
    "    return timm.create_model('vit_small_patch8_224', pretrained=True)\n",
    "\n",
    "# import models and weights\n",
    "from torchvision.models import (\n",
    "    vit_b_32, ViT_B_32_Weights,\n",
    "    vgg11, VGG11_Weights,\n",
    "    vgg11_bn, VGG11_BN_Weights,\n",
    "    resnet18, ResNet18_Weights,\n",
    "    densenet121, DenseNet121_Weights,\n",
    "    mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    ")\n",
    "\n",
    "# models data (name, constructor fn, weights)\n",
    "models = [\n",
    "    ('ViT-S/8', vit_s_8, None),\n",
    "    ('ViT-B/32', vit_b_32, ViT_B_32_Weights),\n",
    "    ('VGG11', vgg11, VGG11_Weights),\n",
    "    ('VGG11 (BN)', vgg11_bn, VGG11_BN_Weights),\n",
    "    ('ResNet18', resnet18, ResNet18_Weights),\n",
    "    ('DenseNet121', densenet121, DenseNet121_Weights),\n",
    "    ('MobileNet V3', mobilenet_v3_small, MobileNet_V3_Small_Weights)\n",
    "]\n",
    "\n",
    "model_accs = {\n",
    "    'vit_s_8': 80., # Approximated\n",
    "    'vit_b_32' : 75.912,\n",
    "    'vgg11' : 69.02,\n",
    "    'vgg11_bn' : 70.37,\n",
    "    'resnet18' : 69.758,\n",
    "    'densenet121' : 74.434,\n",
    "    'mobilenet_v3_small' : 67.668,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "def run_inference(device, model_ctor, weights, batch_size, grad_enabled=False, n_reps=10):\n",
    "    vit_s = weights is None\n",
    "    # load model and preprocessing transforms\n",
    "    if vit_s:  # vit-s/8 is loaded via timm\n",
    "        model = model_ctor()\n",
    "        data_config = timm.data.resolve_model_data_config(model)\n",
    "        transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "        imarray = np.random.rand(100,100,3) * 255\n",
    "        img = Image.fromarray(imarray.astype('uint8')).convert('RGBA')\n",
    "    else:\n",
    "        weights = weights.IMAGENET1K_V1\n",
    "        model = model_ctor(weights=weights, progress=False)\n",
    "        transforms = weights.transforms()\n",
    "        img = torch.rand(1, 3, 224, 224).type(torch.uint8)\n",
    "\n",
    "    # put everything on the device\n",
    "    model.to(device)        \n",
    "\n",
    "    # set model to eval\n",
    "    model.eval()\n",
    "\n",
    "    # init gpu loggers\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    timings = torch.zeros(n_reps)\n",
    "\n",
    "    def prepare_img(img):\n",
    "        if vit_s:\n",
    "            transformed_img = transforms(img)\n",
    "            transformed_img = transformed_img.to(device)\n",
    "        else:\n",
    "            img = img.to(device)\n",
    "            transformed_img = transforms(img)\n",
    "        \n",
    "        transformed_img = transformed_img.repeat(batch_size, 1, 1, 1)\n",
    "        assert transformed_img.shape == (batch_size, 3, 224, 224)\n",
    "        return transformed_img\n",
    "\n",
    "    # memory check\n",
    "    with torch.set_grad_enabled(grad_enabled):\n",
    "        mem_before = torch.cuda.memory_allocated()\n",
    "        _ = model(prepare_img(img))\n",
    "        mem_after = torch.cuda.memory_allocated()\n",
    "\n",
    "    # GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = model(prepare_img(img))\n",
    "\n",
    "    # run inference\n",
    "    with torch.set_grad_enabled(grad_enabled):\n",
    "        for i in range(n_reps):\n",
    "            transformed_img = prepare_img(img)\n",
    "            starter.record()\n",
    "            y_pred_probs = model(transformed_img)\n",
    "            y_pred_probs.argmax(dim=1)\n",
    "            ender.record()\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            elapsed_time = starter.elapsed_time(ender)\n",
    "            timings[i] = elapsed_time\n",
    "    \n",
    "    stats = {\n",
    "        'mean_inference_time': timings.mean().item(),\n",
    "        'memory_usage_before': mem_before,\n",
    "        'memory_usage_after': mem_after,\n",
    "    }\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(b) (2 points) Do you expect the inference speed to increase or decrease without torch.no_grad()? Why? What does torch.no_grad() do? For the same models as in (a), plot the inference speed with and without torch.no_grad()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT-B/32\n",
      "VGG11\n",
      "VGG11 (BN)\n",
      "ResNet18\n",
      "DenseNet121\n",
      "MobileNet V3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_inference_time</th>\n",
       "      <th>memory_usage_before</th>\n",
       "      <th>memory_usage_after</th>\n",
       "      <th>mean_inference_time (grad enabled)</th>\n",
       "      <th>memory_usage_before (grad enabled)</th>\n",
       "      <th>memory_usage_after (grad enabled)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ViT-B/32</th>\n",
       "      <td>37.122356</td>\n",
       "      <td>1099036672</td>\n",
       "      <td>1099292672</td>\n",
       "      <td>39.242653</td>\n",
       "      <td>1099036672</td>\n",
       "      <td>3177423872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG11</th>\n",
       "      <td>19.181057</td>\n",
       "      <td>1277671936</td>\n",
       "      <td>1277927936</td>\n",
       "      <td>19.176142</td>\n",
       "      <td>1277671936</td>\n",
       "      <td>4402684416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG11 (BN)</th>\n",
       "      <td>22.229504</td>\n",
       "      <td>1277721088</td>\n",
       "      <td>1277977088</td>\n",
       "      <td>22.341324</td>\n",
       "      <td>1277721088</td>\n",
       "      <td>6303801856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResNet18</th>\n",
       "      <td>6.819942</td>\n",
       "      <td>793079296</td>\n",
       "      <td>793335296</td>\n",
       "      <td>6.834688</td>\n",
       "      <td>793079296</td>\n",
       "      <td>2214680064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DenseNet121</th>\n",
       "      <td>29.873972</td>\n",
       "      <td>779120128</td>\n",
       "      <td>779376128</td>\n",
       "      <td>29.957325</td>\n",
       "      <td>779120128</td>\n",
       "      <td>9140257792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MobileNet V3</th>\n",
       "      <td>4.605542</td>\n",
       "      <td>756421120</td>\n",
       "      <td>756677120</td>\n",
       "      <td>5.884314</td>\n",
       "      <td>756421120</td>\n",
       "      <td>1808499712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean_inference_time  memory_usage_before  memory_usage_after  \\\n",
       "ViT-B/32                37.122356           1099036672          1099292672   \n",
       "VGG11                   19.181057           1277671936          1277927936   \n",
       "VGG11 (BN)              22.229504           1277721088          1277977088   \n",
       "ResNet18                 6.819942            793079296           793335296   \n",
       "DenseNet121             29.873972            779120128           779376128   \n",
       "MobileNet V3             4.605542            756421120           756677120   \n",
       "\n",
       "              mean_inference_time (grad enabled)  \\\n",
       "ViT-B/32                               39.242653   \n",
       "VGG11                                  19.176142   \n",
       "VGG11 (BN)                             22.341324   \n",
       "ResNet18                                6.834688   \n",
       "DenseNet121                            29.957325   \n",
       "MobileNet V3                            5.884314   \n",
       "\n",
       "              memory_usage_before (grad enabled)  \\\n",
       "ViT-B/32                              1099036672   \n",
       "VGG11                                 1277671936   \n",
       "VGG11 (BN)                            1277721088   \n",
       "ResNet18                               793079296   \n",
       "DenseNet121                            779120128   \n",
       "MobileNet V3                           756421120   \n",
       "\n",
       "              memory_usage_after (grad enabled)  \n",
       "ViT-B/32                             3177423872  \n",
       "VGG11                                4402684416  \n",
       "VGG11 (BN)                           6303801856  \n",
       "ResNet18                             2214680064  \n",
       "DenseNet121                          9140257792  \n",
       "MobileNet V3                         1808499712  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "assert torch.cuda.is_available(), \"Inference should be run on GPU!\"\n",
    "device = 'cuda'\n",
    "n_reps = 10\n",
    "batch_size = 64\n",
    "\n",
    "index = []\n",
    "rows = []\n",
    "for model_name, model_ctor, weights in models[1:]:\n",
    "    print(f'{model_name}')\n",
    "    stats_no_grad = run_inference(device, model_ctor, weights, batch_size, grad_enabled=False, n_reps=n_reps)\n",
    "    stats_grad = run_inference(device, model_ctor, weights, batch_size, grad_enabled=True, n_reps=n_reps)\n",
    "\n",
    "    index.append(model_name)\n",
    "    renamed_stats_grad = {f'{k} (grad enabled)': v for k, v in stats_grad.items()}\n",
    "    stats = {**stats_no_grad, **renamed_stats_grad}\n",
    "    rows.append(stats)\n",
    "\n",
    "df = pd.DataFrame.from_records(rows, index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inference time (grad enabled)</th>\n",
       "      <th>inference time (grad disaabled)</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ViT-B/32</th>\n",
       "      <td>6.876672</td>\n",
       "      <td>4.420813</td>\n",
       "      <td>75.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG11</th>\n",
       "      <td>1.205043</td>\n",
       "      <td>1.091994</td>\n",
       "      <td>69.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG11 (BN)</th>\n",
       "      <td>1.576448</td>\n",
       "      <td>1.413120</td>\n",
       "      <td>70.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResNet18</th>\n",
       "      <td>2.524262</td>\n",
       "      <td>2.098586</td>\n",
       "      <td>69.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DenseNet121</th>\n",
       "      <td>14.973440</td>\n",
       "      <td>12.321484</td>\n",
       "      <td>74.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MobileNet V3</th>\n",
       "      <td>5.348864</td>\n",
       "      <td>4.171162</td>\n",
       "      <td>67.668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              inference time (grad enabled)  inference time (grad disaabled)  \\\n",
       "ViT-B/32                           6.876672                         4.420813   \n",
       "VGG11                              1.205043                         1.091994   \n",
       "VGG11 (BN)                         1.576448                         1.413120   \n",
       "ResNet18                           2.524262                         2.098586   \n",
       "DenseNet121                       14.973440                        12.321484   \n",
       "MobileNet V3                       5.348864                         4.171162   \n",
       "\n",
       "              accuracy  \n",
       "ViT-B/32        75.912  \n",
       "VGG11           69.020  \n",
       "VGG11 (BN)      70.370  \n",
       "ResNet18        69.758  \n",
       "DenseNet121     74.434  \n",
       "MobileNet V3    67.668  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c) (2 points) For the same models as in (a), plot the amount of GPU vRAM (you can check this with code by executing torch.cuda.memory_allocated() or with the terminal using nvidia-smi) while conducting a forward pass with torch.no_grad() and without. Does torch.no_grad() influence the memory usage? Why? Make sure to save the output after the forward pass. Use batch_size=64 and report the memory in MB.\n",
    "\n",
    "Hint: You can create a fake image with torch.rand()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
