#!/bin/bash

#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=CLIPVP-CIFAR10
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=04:00:00
#SBATCH --mem=32000M
#SBATCH --output=slurm_output_%A.out

module purge
module load 2021
module load Anaconda3/2021.05

# activate the environment
source activate dl2022

# Run 1: Visual prompting CLIP on CIFAR-10 with standard text prompt
code_dir=./

# Standard constants
arch="ViT-B/32"
text_prompt_template="This is a photo of a {}"
epochs=5

## Set of experiments on CIFAR-10
dataset="cifar10"
root=~/data/
mkdir -p $root

datasets=(cifar100 cifar10 cifar100 cifar10 cifar100 cifar10)
prompt_nums=(2 2 2 2 2 2)
injection_layers=(2 2 5 5 10 10)
dp_ckpts=(deep_prompt_2_2_cifar100_clip_ViT-B deep_prompt_2_2_cifar10_clip_ViT-B deep_prompt_2_5_cifar100_clip_ViT-B deep_prompt_2_5_cifar10_clip_ViT-B deep_prompt_2_10_cifar100_clip_ViT-B deep_prompt_2_10_cifar10_clip_ViT-B)


for dataset in "${datasets[@]}"; do
    for i in "${!prompt_nums[@]}"; do
        prompt_num=${prompt_nums[$i]}
        injection_layer=${injection_layers[$i]}
        echo "Running experiment on $dataset with deep prompt consisting of $prompt_num tokens at layer $injection_layer"
        python $code_dir/main.py \
            --dataset $dataset \
            --arch $arch \
            --text_prompt_template "$text_prompt_template" \
            --epochs $epochs \
            --prompt_type deep_prompt \
            --prompt_num $prompt_num \
            --injection_layers $injection_layer \
            --root $root
    done
done